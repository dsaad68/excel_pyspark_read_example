# Requiremetns

1. Install pyspark with pip `pip install pyspark`
2. Download Hadoop Wrapper for Windows `winutils` and set the HADOOP_HOME to path ([Guide](https://sparkbyexamples.com/spark/spark-hadoop-exception-in-thread-main-java-lang-unsatisfiedlinkerror-org-apache-hadoop-io-nativeio-nativeiowindows-access0ljava-lang-stringiz/))
3. Download [HadoopOffice](https://github.com/ZuInnoTe/spark-hadoopoffice-ds/releases) jar `spark-hadoopoffice-ds_<scala-version>-<package-version>.jar`
